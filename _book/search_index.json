[["index.html", "Demons and Decisions A Defence of Causal Decision Theory Front Matter", " Demons and Decisions A Defence of Causal Decision Theory Brian Weatherson 2022-04-27 Front Matter Draft of a book in progress defending a novel version of Causal Decision Theory. The view is somewhat customisable using the toolbar above. You can change the font type, the font size, and the background color. And you can download a PDF or EPub version from the toolbar as well. "],["introchap.html", "Chapter 1 Make Defensible Decisions 1.1 Proceduralism and Defensivism 1.2 Games and Decisions 1.3 The Defensible Norm 1.4 The Main Example", " Chapter 1 Make Defensible Decisions A rational chooser knows what they are doing, and thinks that it is for the best. That is, they think that there is nothing else they could be doing that would be better. This book defends a version of decision theory that starts, and largely ends, with this principle. Properly understood, this is all there is to decision theory. But how to properly understand it will be the subject of much of this book. The principle I just stated is backwards looking. It says that the chooser must think that the decision is for the best when they make it. It doesn’t say much about how they come to make that decision, or whether the decision makes sense given the views the chooser has at the start of deliberation. That’s by design. Decision theory is the theory of when decisions can be defended. Or, at least, that’s what I’ll argue in this book. I’m mostly going to be concerned with a special class of decision problems: those involving demons who have spectacular predictive powers. These have been a particular focus of decision theorists for the last half-century. In keeping them center stage I am, in this one respect at least, following tradition. But I will make use of the principle that our theory of how to make decisions when demons are around should be consistent with our theory of how to make decisions when demons are not around. And the motivations for the two parts of the theory should be consistent as well. This turns out to be a somewhat substantive constraint. Demons predict what other people will choose, make moves accordingly, and these moves make a difference to the consequences of other choices. That’s to say, demons behave just like the rational players in orthodox game theory. Interacting with demons is, at a fairly deep level, playing games with them. So we should expect game theory to have something to tell us about how those interactions go. This isn’t a novel point; I owe it to William Harper (1986). But it is going to be central to the plot of this book. The next three sections spell out the points made in each of the last three paragraphs. And then I’ll close the chapter by setting out a generic version of the main example of the book, and going over the plans for the rest of the book. 1.1 Proceduralism and Defensivism The vast bulk of decision theories on the market are what I’ll call proceduralist. That is, they provide a procedure for determining what to do in a given problem. I’m going to argue against proceduralism, and in favor of what I’ll call defensivism. And to do that, it helps to clarify just what is meant by saying that a theory provides a procedure for determining what to do. As I’ll understand it, proceduralism is the conjunction of four claims about what to do in a decision problem. Two of these are about the inputs to deliberation, and two of them are about the outputs. Here are the four claims, with some hopefully useful names. Ex Ante What is to be done is a function of what things are like at the start of deliberation. Transparency The inputs to that function are all knowable as long as the chooser is sufficiently rational and self-aware. Decisiveness In any decision problem, there is only one thing which is to be done, unless there are several things that are equally good. In the latter case, adding a minimal sweetening to any one of the equally good options would make it the option to be chosen. Possibility In any finite decision problem, at least one choice is rationally permissible. That is, there are no finite rational dilemmas. I’m going to argue against all four of these claims. The kind of theory I favor, defensivism, instead endorses the following four claims. Ex Post What is to be done is a function of what things are like at the end of deliberation. Opacity The inputs to that function involve, among other things, what probabilities are rational given the chooser’s evidence, and this may be opaque to the self-aware, rational agent. Indecisiveness In many decision problems, there are permissible options which are not equally good, and there would still be many permissible options after sweetening one or other option. Dilemmas In many finite decision problems, no choice is rationally permissible. That is, there are finite rational dilemmas. Neither Proceduralism nor Defensivism is a package deal; you can mix and match the parts. And there are many natural weakenings of one or other part of the family of views. For instance, in chapter ??, I’ll spend some time on views that say that Decisiveness is only guaranteed to hold in cases where there are just two options. But that said, there are natural affinities between the four parts of Proceduralism. if you thought the point of decision theory was to provide a user’s guide to making decisions, you’ll naturally end up with a proceduralist theory. And lots of theories have done just that. Any theory which starts with a function from states available to the chooser at the start of deliberation to numerical values, and instructs the chooser to maximise that value, will be proceduralist. That very abstract description of a decision theory The first thing to do is to argue against proceduralism. Proceduralism has a pair of input conditions, and a pair of output conditions The input conditions are: - What is to be chosen is a function of what things are like at the start of deliberation - The values that are relevant are knowable to the chooser as long as the chooser is rational The output conditions are: - Decisiveness (if multiple acceptable, then adding a penny breaks tie) - No dilemmas I’m going to reject every part of proceduralism. Note that proceduralism is even more general than what (Elga2021?) calls a ‘suppositional’ decision theory’. Proceduralism is not a package deal - Stalnaker accepts part of it and rejects other parts - but it is tempting to see the whole thing running together. 1.2 Games and Decisions 1.3 The Defensible Norm In this book I’m mostly going to focus on what I’ll call Demonic decision problems. I’ll have much more to say about demons in section 2.5, but for now all we need to know is that demons have the means, motive, and opportunity to correctly predict what strategy a Chooser will adopt. The most famous demonic problem is Newcomb’s Problem (Nozick 1969). The chooser is presented with two boxes, one opaque and one clear. They have a choice between taking just the opaque box, i.e., taking one box, and taking both the opaque and the clear box, i.e., taking two boxes. The clear box has a good of value \\(y\\) in it. The contents of the opaque box are unknown. A demon has predicted the chooser’s choice, and has placed a good of value \\(x\\) in it if they predict the chooser will take one box, and left it empty (which we’ll assume has value 0) if they predict the chooser will take both boxes. The key constraint is \\(x &gt; y\\). In most versions the value given for \\(x\\) is massively greater than that for \\(y\\), but the theories that are developed for the problem typically are sensitive only to whether \\(x\\) is larger than \\(y\\), not to how much larger it is. The demon is really good at their job. They are not a time traveller; they are making a prediction that is not causally influenced by what the Chooser actually does. But they are really good. I’ll assume that they are arbitrarily good, and come back to just what I mean by that in section 2.5. I’ll write 1 and 2 for the two choices, and P1 and P2 for the predictions. In general, where there is a demon who makes these kinds of predictions, I’ll write ‘PX’ to mean the state of choice X being predicted. So here is the decision problem. Table 1.1: Newcomb’s Problem P1 P2 1 \\(x\\) 0 2 \\(x + y\\) \\(y\\) A large part of late 20th Century decision theory was given over to discussing this problem. So-called Causal Decision Theorists argued in favor of taking both boxes. The primary argument is that whatever the demon has done, the chooser gets a bonus of \\(y\\) for taking the second box. It’s good to get guaranteed bonuses, so they should take the bonus. This is basically the view I’m going to defend in this book, though with a number of deviations from the way it was defended in these classic works. So-called Evidential Decision Theorists argued in favor of taking just the one box. The primary argument is that the chooser who takes one box expects to get \\(x\\), the chooser who expects to get both boxes expects to get \\(y\\), it’s better to take a choice that one expects to do better, and \\(x &gt; y\\), so it’s better to take one box. Insert citations to each side Both of these arguments can be given little dramatisations, though I have my doubts in each case about how much these dramatisations add to the force of the argument. The dramatisation for the one-box argument involves the chooser being part of a number of people taking part in this choice procedure. Ahead of them, they see a stream of people going into the room to interact with the demon, and those who chose one-box coming out with \\(x\\), while those who chose two-boxes came out with \\(y\\). If \\(x &gt;&gt;&gt; y\\), as in the most common version, we can imagine that the emotional reactions of these people to the interaction are quite different. And the chooser very much wants to be part of the happier group, which it seems they will be iff they choose one-box. The dramatisation for the two-box argument involves postulating a well-meaning friend Insert citation. Imagine that the chooser has a friend who has their interests at heart, and can see into the opaque box. Perhaps the box is clear at the back, and the friend is standing behind the boxes. The friend will want the chooser to take both boxes, whatever they see. And the chooser knows that the friend will think this, even without knowing what the friend knows. And the chooser knows the friend would think this, even without the friend existing. That is, even in the original game, with no friend, they know what such a friend would think. And they should defer to that friend, since they are better informed. So they should take both boxes. The example involving the friend can be used to generate an interesting variant of Newcomb’s Puzzle, due to Frank Arntzenius (2008). Keep the contents of the boxes the same, including that the demon puts \\(x\\) into the first box iff the demon predicts only one box will be taken. But this time both boxes are clear. Now the chooser has the same view as the well-meaning friend. What should they do? We can model this problem using the following decision tree. Insert drawing of tree This representation should look familiar from game theory textbooks. It’s just a standard extensive form representation of a game where each player makes one move. But perhaps it isn’t obvious just how deep the analogy to game theory is. As William Harper (1986) notes, the original Newcomb problem can be thought of as a game too. It’s a simultaneous move game. Of course, the moves aren’t made simultaneously; it’s crucial to the story that the money in the first box is there (or isn’t) while the chooser decides. But what matters in game theory is when the moves are revealed, not when they are made, and they are revealed simultaneously, so it’s a simultaneous move game. And we know the payouts for the demon. The demon gets payout 1 if the prediction is correct, and payout 0 if the prediction is incorrect. That’s not to say that the demon will actually be given some monetary reward for a correct prediction. Rather, it’s that what it is in game theory for one to have a value function just is for one’s actions to make sense assuming that one is aiming to maximise that function. And the demon clearly is aiming at maximising the function that takes value 1 when the prediction is correct, and 0 when it is incorrect. So that’s the demon’s value function. With this in mind, we can redraw the game tree with both player’s payouts listed. Insert drawing of tree with both payouts I’ve put the demon’s payouts second, even though the demon moves first. The focus here is on the chooser, so they are player 1. When a game representation lists the payout in a situation as \\(a, b\\) that means that player 1 gets \\(a\\) and player 2 gets \\(b\\). In this case that means the chooser gets \\(a\\) and the demon gets \\(b\\). In this book I’m mostly going to work with games where the demon’s payouts are either 1 for a correct prediction of 0 for an incorrect one. But once we’ve got the basic concept of the demon as a player getting payouts, we can set the demon up with other payouts too. And then we can bring just about any tool we like from contemporary game theory to bear on demonic decision theory. And that move, which I should stress is really taken straight from Harper (1986), is going to be the central move in this book. Here is what the original Newcomb problem looks like when we follow Harper’s lead and transform it into a game. Table 1.2: Newcomb’s Problem as a Game P1 P2 1 \\(x, 1\\) \\(0, 0\\) 2 \\(x + y, 0\\) \\(y, 1\\) 1.4 The Main Example Figure 1.1: Generic version of the main example "],["make-defensible-decisions.html", "Chapter 2 Make Defensible Decisions 2.1 Why Do Ideal Decision Theory 2.2 Why Do Decision Theory? 2.3 Decision Theory and Making Decisions 2.4 Methodology 2.5 About a Demon", " Chapter 2 Make Defensible Decisions 2.1 Why Do Ideal Decision Theory This one is actually harder for the proceduralist to answer, but it’s a challenge for us too. 2.2 Why Do Decision Theory? The proceduralist has an answer - to advise about decision problems. What’s our answer? 2.3 Decision Theory and Making Decisions Roughly, proceduralism must be right because decision theory is a theory of how to make decisions. No, because of nuclear war cases 2.4 Methodology 2.5 About a Demon Include stuff about arbitrarily accurate Note that known perfect accuracy leads to challenges, one’s we’ll come back to in… Also note that we’re assuming the demon predicts the strategy a player chooses. That could include randomisation. Note that I’m simply assuming expected utility theory is right for non-demonic problems. But that does imply an assumption that there is some reason for that. And I think that’s got to include something like a Sure Thing Principle. But I am including the open box Newcomb Problem as demonic. And maybe a riff on why it’s Player/Chooser/Agent whatever "],["against-decisiveness.html", "Chapter 3 Against Decisiveness", " Chapter 3 Against Decisiveness "],["against-rational-possibility.html", "Chapter 4 Against Rational Possibility 4.1 The Possibility Assumption in Philosophical Arguments 4.2 Dilemmas in Simple Games 4.3 Mixed Strategies to the Rescue? 4.4 What Dilemmas are Like", " Chapter 4 Against Rational Possibility 4.1 The Possibility Assumption in Philosophical Arguments The bad argument against utility theory - pick a number in [0, 1), every positive is ruled out so 0 huh?! The recent PQ article as an example of the same kind of thing 4.2 Dilemmas in Simple Games Death in Damascus, including asymmetric Versions of the ABC game Intuitively these just are dilemmas Note that Nash doesn’t match up with intuition here 4.3 Mixed Strategies to the Rescue? Why we might think mixed strategies will help here Problem one - maybe that’s unintuitive - I’m not moved; I think rational players can do ok at rock paper scissors Problem two - the [0, 1) choice Problem three - the Econometrica 1995 paper example, which I’ll have to find again Feels like this won’t really get us out of the jam even if you think, as I do, that others have been too quick to say chooser is rational but can’t mix 4.4 What Dilemmas are Like Be like a smart rationally constrained person Use heuristics that work much of the time, on average This might end up looking a lot like EDT Maybe this is why Newcomb’s Problem is so hard "],["against-coherence-norms.html", "Chapter 5 Against Coherence Norms 5.1 Coherence for the Incoherent 5.2 Coherence is a Substantive Norm 5.3 Coherence in Signaling Games", " Chapter 5 Against Coherence Norms Some say decision theory is just about doing well by one’s own lights. I follow Comesana 2020 in saying rational action requires rational belief. Actually doesn’t quite require - Knight’s kid playing in the field is fine And I mean I think something stronger than Comesana - I mean that there isn’t anything extra good re coherence 5.1 Coherence for the Incoherent What is it to do best by one’s own lights If one believes p, q -&gt; -p, and q, is it best to act as if p, or as if q At best we can get rules for how to be more coherent if you are a bit coherent And that’s maybe something, but not a lot But even this requires there being a gap between coherence norms and evidence norms, and I don’t think there is 5.2 Coherence is a Substantive Norm Summarise Worsnip book Intuition about guy who punches self in head because he thinks it will mean some trivial thing he cares about is realised Intuition about guy who goes from p to p v q1, p v q2, etc, etc, all day every day Intuition that Dummett/Priest etc are, if wrong about anything, wrong about a substantive matter Worsnip response - everyone has a tendency to be coherent Response - what, and I cannot stress this enough, the f There is no way that’s a correct description of the dialethist, the intuitionist, etc 5.3 Coherence in Signaling Games So far I’ve offered the following argument against the view that decision theory is only about how people should act given their existing beliefs and desires, and has no interest in the rationality of the beliefs. The view does not make sense when applied to people whose beliefs are not just irrational, but incoherent. So the view needs a distinction between coherence norms on belief, which must be satisfied for decision theory to be applicable, and substantive norms on belief, which are irrelevant to decision theory. But thinking about heterodox logicians reveals that there is no distinction to be found here. So, the view does not ultimately make sense. Here I want to change tack and offer a direct argument, from with decision theory, for the argument that the decision-theoretic notion of rational action is sensitive to the rationality of the chooser’s underlying beliefs. The argument is going to be that the best solution to the beer-quiche game (ChoKreps1985?) requires that we look at the rationality of the underlying beliefs, not just at which actions flow in the right way from existing beliefs. To start, let’s translate the beer-quiche game into decision-theoretic terms, using an arbitrarily accurate demon. The problem is a little more complicated than Newcomb-like problems often are, but it should be reasonably familiar if one is used to the kind of signaling games first developed by David Lewis (1969). The game goes through the following stages. Both Chooser and Demon are informed of all the following facts, and it is made clear that they are common knowledge. Chooser is randomly assigned to one of two types, which we’ll call \\(u\\) and \\(d\\), for Up and Down. This assignment is done by a random device which has an 0.6 chance of assigning Chooser to \\(u\\), and an 0.4 chance of assigning Chooser to \\(d\\). Demon is not told of the assignment, and cannot predict how random devices work. Chooser will then make a choice of two options, which we will label \\(U\\) and \\(D\\). Demon will be told which option Chooser takes. Demon will then try to guess which type Chooser is. In making this guess, Demon will use their arbitrarily good ability to predict Chooser’s strategy. The strategy, in the relevant sense, is Chooser’s function from type assignment to choice. Chooser can randomise, so a function is a pair of probabilities - what probability of selecting \\(U\\) if they are type \\(u\\), and what probability of selecting \\(U\\) if they are type \\(d\\). Chooser gets 2 utils if Demon predicts they are type \\(u\\), and 1 util if their choice ‘matches’ their type, i.e., if they select \\(U\\) if they are \\(u\\) or \\(D\\) if they are \\(d\\). Demon gets 1 util if their guess is correct. Here is the game in graphical form. Figure 5.1: A Signaling Game The game starts in the middle. Nature assigns Chooser to a type, and we move either up, if they are assigned \\(u\\), or down, if they are assigned \\(d\\). Then Chooser chooses an option. We move left if they choose \\(U\\), and right if they choose \\(R\\). Then Demon chooses, and we move up or down on the angled lines. The dotted lines around the two nodes are there because Demon doesn’t know precisely which node they are at. They know what Chooser chose, the nodes inside the dashed lines are alike in that respect. But they don’t know which type assignment was made. And then we get the payouts, using the formulae in lines 6 and 7. Note that while Demon can perfectly predict Chooser’s strategy, it doesn’t follow that they will perfectly predict Chooser’s type. This can be true even if Chooser uses a non-probabilistic strategy. In particular, it is true if Chooser adopts what’s called a pooling strategy, of playing the same option whatever type they are. If Chooser plays \\(U\\) whether they are \\(u\\) or \\(d\\), the Demon will get no information from the play, and have to use their prior credence that Chooser has an 0.6 chance of being \\(u\\). And so, it will be expected utility maximising for Demon to guess that Chooser is \\(u\\), and that’s what they will do. And the same goes for the situation where Chooser’s strategy is to play \\(D\\) no matter what. The non-pooling strategies, on the other hand, are not stable. If Chooser gives Demon information about their type, that will mean Demon is more likely to accurately guess their type. And that’s bad news for choosers who are of type \\(d\\). But since Chooser knows their type when they act, they will not perform an act that’s bad for their type. So they will not do anything other than play one of the two pooling strategies. (I’m glossing over a lot of the details here, but this is well worked out territory. See, inter alia, (ChoKreps1985?) for the more careful version of the argument in this paragraph.) So Chooser will play a pooling strategy. But which one will they play? Playing \\(U\\) makes sense. If they are of type \\(u\\), then they will get the best possible return, so they will be happy to follow through on the strategy. And if they are of type \\(d\\), they will get a return of 2 from this strategy, and a return of 1 if they deviate from the strategy and play \\(D\\). The best solution to beer-quiche puts constraints on priors These aren’t coherence constraints in any recognisable sense But they are the kind of thing decision theory should take into account So decision theory should take substantive notions of rationality into account "],["responding-to-evidential-decision-theory.html", "Chapter 6 Responding to Evidential Decision Theory 6.1 So Why Ain’t You Rich? 6.2 To Bet the Impossible Bet", " Chapter 6 Responding to Evidential Decision Theory 6.1 So Why Ain’t You Rich? From existing paper 6.2 To Bet the Impossible Bet The Ahmed cases all go away if you focus on what’s possible at the end of deliberation, not at the start of it This might require some contextualism about ability, a la Hawthorne and Pettit, to really make stick "],["epistemic-uniqueness-and-decisiveness.html", "Chapter 7 Epistemic Uniqueness and Decisiveness", " Chapter 7 Epistemic Uniqueness and Decisiveness "],["puzzles-about-weak-dominance.html", "Chapter 8 Puzzles about Weak Dominance 8.1 Why Weak Dominance 8.2 Three Kinds of Demon 8.3 Iterated Weak Dominance", " Chapter 8 Puzzles about Weak Dominance 8.1 Why Weak Dominance Basic ABC example. Demon might not give a choice but if they do Up beats Down This doesn’t require weak dominance but that’s the simplest explanation Also fits with the “can you defend this” But two puzzles for the next two sections 8.2 Three Kinds of Demon Set up red green game and properly cite Note this is my third try at it First demon, limit prob. This one is easy Second demon, zero prob but possible. Answer one this can’t happen. But this takes us into infinitesimal territory and I’m not going there. Answer two, the speech sounds bad. Don’t take uncompensated risks. Third demon, can not fail. Then not in fact weak dominance post choice bc alternative is not in fact possible. Same goes for symmetric humans but third is really impossible. 8.3 Iterated Weak Dominance Sometimes thought that if WD then committed to IWD. Cite HH and Stalnaker in reply. Three objections 1. Order effects 2. Gets unintuitive results 3. Nothing incoherent about speeches that violate Start with Bonanno on order effects Do strategic version of money burning and show what IWD leads to Note that nothing wrong with all H speech This might get complicated Now do dynamic version Really absurd that having an untaken option can make a difference, when others know you won’t take it But does HH mean that you think demon is stupid? No it means that you think demon might follow up stupid with stupid Also do this using counterfactuals maybe "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
